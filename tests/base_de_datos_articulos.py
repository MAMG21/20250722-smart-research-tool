# -*- coding: utf-8 -*-
"""Base de datos articulos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jABf9_amHZvnniLQHiWNg9NP6VdRuf5W

BASES DE DATOS PARA CALCULO DE INDICE H


A continuacion se muestran todos los resultados de busqueda en open alex para el autor Geoffrey E. Hinton a5108093963 y unicamente se filtran todos sus articulos:

En el siguiente link se puede ver que la informacion obtenida desde la API de openalex es igual a la obtenida directamente de la pagina web, se arroja la misma cantidad de resultados:


https://openalex.org/works?page=1&filter=authorships.author.id:a5108093963,type:types/article&per_page=100

A continuacion se muestra el perfil del autor en open alex:

https://openalex.org/authors/a5108093963
"""

import requests
import pandas as pd
import time

# Nombre del autor
author_name = "Yann LeCun" # Puedes cambiarlo por "Yann LeCun", "Ilya Sutskever", "Geoffrey E. Hinton"
polite_email = "tu_email@ejemplo.com"  # Reemplaza por tu correo real

# --- Paso 1: Buscar ID del autor por nombre ---
author_search_url = "https://api.openalex.org/authors"
params = {
    "search": author_name,
    "mailto": polite_email
}

try:
    print(f"üîç Buscando autor: {author_name}")
    resp = requests.get(author_search_url, params=params)
    resp.raise_for_status()
    data = resp.json()
    results = data.get("results", [])

    if not results:
        print("‚ùå No se encontr√≥ ning√∫n autor con ese nombre.")
        exit()

    # Tomamos el primer resultado como el autor deseado
    author = results[0]
    author_id = author['id'].split('/')[-1]  # Extrae solo el ID
    author_display_name = author['display_name']
    print(f"‚úÖ Autor encontrado: {author_display_name} (ID: {author_id})")

except requests.exceptions.RequestException as e:
    print(f"‚ùå Error al buscar el autor: {e}")
    exit()

# --- Paso 2: Obtener TODAS LAS PUBLICACIONES del autor ---
base_url = "https://api.openalex.org/works"
results_per_page = 200  # M√°ximo permitido por OpenAlex

all_rows = []
page = 1
while True:
    # --- CAMBIO PRINCIPAL AQU√ç ---
    # Se elimin√≥ ",type:article" del filtro para obtener todos los tipos de trabajos.
    params = {
        "filter": f"authorships.author.id:{author_id}",
        "per-page": results_per_page,
        "page": page,
        "mailto": polite_email
    }

    try:
        print(f"üìÑ Obteniendo p√°gina {page} de publicaciones...")

        resp = requests.get(base_url, params=params)
        resp.raise_for_status()
        data = resp.json()

        works = data.get("results", [])
        if not works:
            print("‚úÖ No se encontraron m√°s resultados. Proceso completado.")
            break

        for w in works:
            authorships = w.get("authorships", [])
            author_names = [a["author"].get("display_name", "N/A") for a in authorships if a.get("author")] if authorships else []
            concepts = w.get("concepts", [])
            concept_names = [c.get("display_name", "N/A") for c in concepts if c] if concepts else []

            all_rows.append({
                "id": w.get("id"),
                "doi": w.get("doi"),
                "title": w.get("display_name"),
                "type": w.get("type"), # <-- Opcional: Puedes a√±adir el tipo de publicaci√≥n
                "year": w.get("publication_year"),
                "authors": "; ".join(author_names),
                "topics": "; ".join(concept_names),
                "citations": w.get("cited_by_count"),
                "author_name": author_display_name,
                "author_id": author_id
            })

        page += 1
        time.sleep(0.1)

    except requests.exceptions.RequestException as e:
        print(f"‚ùå Error en la solicitud a la API en la p√°gina {page}: {e}")
        break
    except Exception as e:
        print(f"‚ùå Ocurri√≥ un error inesperado: {e}")
        break

# --- Guardado de todos los resultados ---
if all_rows:
    df = pd.DataFrame(all_rows)
    output_filename = "openalex_autor_articulos.csv"  # ‚Üê Nombre fijo para todos los autores
    df.to_csv(output_filename, index=False, encoding="utf-8")

    total_articles = len(all_rows)
    print(f"üöÄ Se encontraron un total de {total_articles} art√≠culos.")
    print(f"üíæ Metadata guardada en '{output_filename}'")

    # --- Imprimir resumen final ---
    print(f"\nüìå Autor: {author_display_name}")
    print(f"üßæ Total de art√≠culos encontrados: {total_articles}")
else:
    print("No se encontraron art√≠culos para guardar.")

"""A continuacion se calculan los siguientes indices en base a la informacion calculada anteriormente:

--- Resultados de las M√©tricas Bibliom√©tricas ---
√çndice H (h-index):
√çndice G (g-index):
√çndice E (e-index):
√çndice M (m-index):
"""

# --- SCRIPT PARA CALCULAR √çNDICES ---
import pandas as pd
import numpy as np
import datetime

try:
    # Cargar el archivo CSV generado en el paso anterior
    file_path = "openalex_autor_articulos.csv"
    df = pd.read_csv(file_path)

    # Preparar los datos de citas y a√±os
    df['citations'] = pd.to_numeric(df['citations'], errors='coerce').fillna(0)
    df['year'] = pd.to_numeric(df['year'], errors='coerce')

    # Validar que haya citas
    if df['citations'].dropna().empty:
        raise ValueError("No hay citas v√°lidas para calcular los √≠ndices.")

    citations = df['citations'].sort_values(ascending=False).tolist()
    print(f"üìä Se cargaron {len(citations)} art√≠culos para el an√°lisis.")

    # C√°lculo del √çndice H
    h_index = 0
    for i, c in enumerate(citations):
        if c >= i + 1:
            h_index = i + 1
        else:
            break

    # C√°lculo del √çndice G
    g_index = 0
    cumulative_citations = 0
    for i, c in enumerate(citations):
        cumulative_citations += c
        if cumulative_citations >= (i + 1)**2:
            g_index = i + 1
        else:
            break  # Mejora: evitar iteraciones innecesarias

    # C√°lculo del √çndice E
    e_index = 0.0
    if h_index > 0:
        h_core_citations = citations[:h_index]
        excess_citations = sum(c - h_index for c in h_core_citations)
        e_index = np.sqrt(excess_citations) if excess_citations > 0 else 0.0

    # C√°lculo del √çndice M
    m_index = 0.0
    valid_years = df['year'].dropna()
    valid_years = valid_years[valid_years >= 1900]  # Validaci√≥n extra
    if h_index > 0 and not valid_years.empty:
        first_publication_year = int(valid_years.min())
        current_year = datetime.datetime.now().year
        career_length = current_year - first_publication_year
        m_index = h_index / max(1, career_length)


        # Obtener nombre del autor desde la columna 'author_name'
    if 'author_name' in df.columns and not df['author_name'].isna().all():
        author_name = df['author_name'].dropna().iloc[0]
    else:
        author_name = "NOMBRE AUTOR"

    total_articulos = len(citations)
    print(f"\nüìå Para el autor {author_name} y para un total de {total_articulos} art√≠culos usados, se obtuvieron los siguientes resultados.")

    # Mostrar Resultados
    print("\n--- Resultados de las M√©tricas Bibliom√©tricas ---")
    print(f"√çndice H (h-index): {h_index}")
    print(f"√çndice G (g-index): {g_index}")
    print(f"√çndice E (e-index): {e_index:.2f}")
    print(f"√çndice M (m-index): {m_index:.2f}")
    print("-------------------------------------------------")



except FileNotFoundError:
    print(f"‚ùå Error: No se encontr√≥ el archivo '{file_path}'.")
    print("Por favor, aseg√∫rate de que el script del 'Paso 1' se haya ejecutado correctamente.")
except Exception as e:
    print(f"‚ùå Ocurri√≥ un error inesperado durante el c√°lculo: {e}")

"""CALCULO DEL INDICE B"""

import pandas as pd
import numpy as np

# Cargar el archivo generado desde OpenAlex
df = pd.read_csv("openalex_autor_articulos.csv")

# Asegurar que las citas est√©n en formato num√©rico
df["citations"] = pd.to_numeric(df["citations"], errors="coerce").fillna(0)

# Ordenar los art√≠culos de mayor a menor seg√∫n n√∫mero de citas
df_sorted = df.sort_values(by="citations", ascending=False)

# C√°lculo del √≠ndice H (por si no lo tienes guardado)
h_index = 0
citations_list = df_sorted["citations"].tolist()
for i, c in enumerate(citations_list):
    if c >= i + 1:
        h_index = i + 1
    else:
        break

# Extraer el n√∫cleo H (los h art√≠culos m√°s citados)
core_h_citations = citations_list[:h_index]

# C√°lculo del √≠ndice B
b_index = np.sqrt(sum(core_h_citations))

# Mostrar resultado
print(f"üìö √çndice H: {h_index}")
print(f"üìà √çndice B: {b_index:.2f}")

CALCULO DEL INDICE V

# --- C√°lculo del √çndice V (V-index) ---
try:
    if 'h_index' in locals() and 'g_index' in locals():
        v_index = (h_index + g_index) / 2
        print(f"‚úÖ √çndice V (V-index) calculado correctamente.")
        print(f"üìê V = (H + G) / 2 = ({h_index} + {g_index}) / 2 = {v_index:.2f}")
    else:
        raise ValueError("No se encontraron las variables 'h_index' y 'g_index'. Verifica que la celda anterior haya sido ejecutada correctamente.")
except Exception as e:
    print(f"‚ùå Error al calcular el √≠ndice V: {e}")

"""CALCULO DE INDICE H RELATIVO


### √çndice H Relativo

El **√≠ndice H relativo** (tambi√©n conocido como *relative h-index*) fue propuesto por **Batista et al. (2006)** como una forma de **normalizar el √≠ndice H** de un investigador en relaci√≥n con su comunidad acad√©mica. Esta m√©trica permite realizar comparaciones m√°s justas entre investigadores de distintas disciplinas, edades acad√©micas o contextos institucionales.

Se define como el **cociente entre el √≠ndice H del investigador y el mayor √≠ndice H observado** dentro de un conjunto de comparaci√≥n (por ejemplo, investigadores de la misma disciplina o cohorte acad√©mica):

\[
h_{\text{relativo}} = \frac{h}{h_{\text{m√°x}}}
\]

Donde:
- \( h \): √≠ndice H del investigador.
- \( h_{\text{m√°x}} \): mayor √≠ndice H observado en el grupo de comparaci√≥n.

Esta m√©trica toma valores entre 0 y 1, donde **1 representa el mayor impacto relativo** dentro del grupo.

#### üìò Referencia (formato APA):
Batista, P. D., Campiteli, M. G., Kinouchi, O., & Martinez, A. S. (2006). Is it possible to compare researchers with different scientific interests? *Scientometrics*, 68(1), 179‚Äì189. https://doi.org/10.1007/s11192-006-0090-4





"""

h_index_autor = 147
h_indices_otros = [95, 82, 120, 135, 147, 168, 103]  # h de otros autores comparables

h_max = max(h_indices_otros)
h_relativo = h_index_autor / h_max if h_max > 0 else 0

print(f"H relativo: {h_relativo:.4f}")

import requests
import pandas as pd
from datetime import datetime
import matplotlib.pyplot as plt

# Par√°metros
FIELD_NAME = "artificial intelligence"
PER_PAGE = 200  # M√°ximo permitido por OpenAlex
NUM_PAGES = 55   # Puedes ajustar para m√°s datos

# Funci√≥n para obtener trabajos de OpenAlex
def fetch_ai_papers(field, per_page=200, num_pages=5):
    all_citation_counts = []
    for page in range(1, num_pages + 1):
        url = f"https://api.openalex.org/works"
        params = {
            "filter": f"concepts.display_name.search:{field}",
            "sort": "cited_by_count:desc",
            "per-page": per_page,
            "page": page
        }
        print(f"Fetching page {page}...")
        response = requests.get(url, params=params)
        data = response.json()
        for work in data.get("results", []):
            citations = work.get("cited_by_count", 0)
            all_citation_counts.append(citations)
    return all_citation_counts

# Calcular H-index
def calculate_h_index(citations):
    citations_sorted = sorted(citations, reverse=True)
    h = sum(1 for i, c in enumerate(citations_sorted, 1) if c >= i)
    return h

# Calcular Hmax
def calculate_hmax(citations):
    return max(citations) if citations else 0

# Ejecutar
citations = fetch_ai_papers(FIELD_NAME, PER_PAGE, NUM_PAGES)
h_index = calculate_h_index(citations)
hmax = calculate_hmax(citations)
relative_h = h_index / hmax if hmax > 0 else 0

# Mostrar resultados
print(f"Fecha: {datetime.now().date()}")
print(f"H-index: {h_index}")
print(f"Hmax (m√°ximo de citas): {hmax}")
print(f"H relativo: {relative_h:.4f}")

# Guardar en DataFrame
df_result = pd.DataFrame([{
    "Fecha": datetime.now().date(),
    "H_index": h_index,
    "Hmax": hmax,
    "H_relativo": relative_h
}])

# Mostrar tabla
df_result

# Opcional: graficar evoluci√≥n si guardas varias semanas
# pd.read_csv("historial_hrel.csv").append(df_result).to_csv("historial_hrel.csv", index=False)

import requests
import json

# --- CONFIGURACI√ìN ---
# ¬°IMPORTANTE! Reemplaza esto con tu correo electr√≥nico.
# OpenAlex lo pide para un acceso "educado" a la API (polite access).
tu_correo = "tu.correo@ejemplo.com"
field_name = "Artificial intelligence"

# --- PASO 1: Encontrar el ID del concepto ---
concept_search_url = "https://api.openalex.org/concepts"
params_concept = {
    'filter': f'display_name.search:{field_name}',
    'mailto': tu_correo
}

try:
    print(f"Buscando el ID para el campo: '{field_name}'...")
    response_concept = requests.get(concept_search_url, params=params_concept)
    response_concept.raise_for_status() # Lanza un error si la solicitud HTTP falla

    data_concept = response_concept.json()

    if data_concept.get('results'):
        concept_id = data_concept['results'][0]['id']
        concept_name = data_concept['results'][0]['display_name']
        print(f"‚úÖ Concepto encontrado: '{concept_name}' con ID: {concept_id}\n")

        # --- PASO 2: Encontrar el autor con el h-index m√°s alto (h-max) ---
        author_search_url = "https://api.openalex.org/authors"

        # Par√°metros para encontrar al autor con el h-index m√°s alto
        # Se a√±ade el 'mailto' tambi√©n en esta solicitud
        params_author = {
            'filter': f'concepts.id:{concept_id}',
            'sort': 'h_index:desc',
            'per_page': 1,
            'select': 'display_name,summary_stats',
            'mailto': tu_correo  # Par√°metro clave para evitar el error 403
        }

        print("Buscando el autor con el h-index m√°s alto (h-max)...")
        response_author = requests.get(author_search_url, params=params_author)
        response_author.raise_for_status()

        data_author = response_author.json()

        if data_author.get('results'):
            top_author = data_author['results'][0]
            author_name = top_author.get('display_name', 'Nombre no disponible')

            # Navegamos de forma segura por la estructura JSON
            if top_author.get('summary_stats'):
                h_max = top_author['summary_stats'].get('h_index', 'No disponible')
            else:
                h_max = 'No disponible'

            # --- RESULTADO FINAL ---
            print("\n" + "="*40)
            print("         RESULTADO DEL C√ÅLCULO DE H-MAX")
            print("="*40)
            print(f"CAMPO DE ESTUDIO:    '{concept_name}'")
            print(f"AUTOR CON MAYOR H:   {author_name}")
            print(f"VALOR H-MAX:         {h_max}")
            print("="*40)

        else:
            print("‚ùå No se encontraron autores para este campo.")

    else:
        print(f"‚ùå No se pudo encontrar el concepto '{field_name}' en OpenAlex.")

except requests.exceptions.HTTPError as e:
    print(f"‚ùå Error HTTP: {e}")
    print("Verifica que tu correo sea v√°lido y que la API de OpenAlex est√© funcionando.")
except requests.exceptions.RequestException as e:
    print(f"‚ùå Error de Conexi√≥n: {e}")
except KeyError as e:
    print(f"‚ùå Error de Datos: No se encontr√≥ la clave esperada en la respuesta de la API: {e}")

"""INSTALACION DE LA LIBRERIA PYBIBX

PYBIBX es un paquete para hacer analisis Bibliometrico y Cienciometrico

-------------------------------

BUSQUEDA EN OPEX ALEX POR AUTOR Y ARTICULOS

A continuacion se muestran todas las 175 variables que contiene la base de datos de open alex, ademas se hace una analisis exploratorio de las variables mas relevantes que puedan ayudarnos a calcular metricas alternativas.

Se pone un ejemplo de busqueda de un autor y se limita la busqueda solamente a articulos academicos:

Geoffrey Hinton && articles

https://openalex.org/works?page=1&filter=authorships.author.id:a5108093963,type:types/article&per_page=100

-------------------------------

Se han identificado 175 variables en la lista proporcionada.

Aqu√≠ tienes la lista completa de las variables:

  * id
  * doi
  * title
  * display\_name
  * publication\_year
  * publication\_date
  * language
  * type
  * type\_crossref
  * indexed\_in
  * institution\_assertions
  * countries\_distinct\_count
  * institutions\_distinct\_count
  * corresponding\_author\_ids
  * corresponding\_institution\_ids
  * apc\_list
  * apc\_paid
  * fwci
  * has\_fulltext
  * cited\_by\_count
  * is\_retracted
  * is\_paratext
  * locations\_count
  * best\_oa\_location
  * datasets
  * versions
  * referenced\_works\_count
  * referenced\_works
  * related\_works
  * cited\_by\_api\_url
  * updated\_date
  * created\_date
  * ids.openalex
  * ids.mag
  * primary\_location.is\_oa
  * primary\_location.landing\_page\_url
  * primary\_location.pdf\_url
  * primary\_location.source.id
  * primary\_location.source.display\_name
  * primary\_location.source.issn\_l
  * primary\_location.source.issn
  * primary\_location.source.is\_oa
  * primary\_location.source.is\_in\_doaj
  * primary\_location.source.is\_indexed\_in\_scopus
  * primary\_location.source.is\_core
  * primary\_location.source.host\_organization
  * primary\_location.source.host\_organization\_name
  * primary\_location.source.host\_organization\_lineage
  * primary\_location.source.host\_organization\_lineage\_names
  * primary\_location.source.type
  * primary\_location.license
  * primary\_location.license\_id
  * primary\_location.version
  * primary\_location.is\_accepted
  * primary\_location.is\_published
  * open\_access.is\_oa
  * open\_access.oa\_status
  * open\_access.oa\_url
  * open\_access.any\_repository\_has\_fulltext
  * citation\_normalized\_percentile.value
  * citation\_normalized\_percentile.is\_in\_top\_1\_percent
  * citation\_normalized\_percentile.is\_in\_top\_10\_percent
  * cited\_by\_percentile\_year.min
  * cited\_by\_percentile\_year.max
  * biblio.volume
  * biblio.issue
  * biblio.first\_page
  * biblio.last\_page
  * primary\_topic.id
  * primary\_topic.display\_name
  * primary\_topic.score
  * primary\_topic.subfield.id
  * primary\_topic.subfield.display\_name
  * primary\_topic.field.id
  * primary\_topic.field.display\_name
  * primary\_topic.domain.id
  * primary\_topic.domain.display\_name
  * fulltext\_origin
  * ids.doi
  * best\_oa\_location.is\_oa
  * best\_oa\_location.landing\_page\_url
  * best\_oa\_location.pdf\_url
  * best\_oa\_location.source.id
  * best\_oa\_location.source.display\_name
  * best\_oa\_location.source.issn\_l
  * best\_oa\_location.source.issn
  * best\_oa\_location.source.is\_oa
  * best\_oa\_location.source.is\_in\_doaj
  * best\_oa\_location.source.is\_indexed\_in\_scopus
  * best\_oa\_location.source.is\_core
  * best\_oa\_location.source.host\_organization
  * best\_oa\_location.source.host\_organization\_name
  * best\_oa\_location.source.host\_organization\_lineage
  * best\_oa\_location.source.host\_organization\_lineage\_names
  * best\_oa\_location.source.type
  * best\_oa\_location.license
  * best\_oa\_location.license\_id
  * best\_oa\_location.version
  * best\_oa\_location.is\_accepted
  * best\_oa\_location.is\_published
  * apc\_list.value
  * apc\_list.currency
  * apc\_list.value\_usd
  * ids.pmid
  * primary\_location.source
  * apc\_paid.value
  * apc\_paid.currency
  * apc\_paid.value\_usd
  * ids.pmcid
  * primary\_location
  * abstract
  * citation\_normalized\_percentile
  * primary\_topic
  * authorships.author\_position
  * authorships.institutions
  * authorships.countries
  * authorships.is\_corresponding
  * authorships.raw\_author\_name
  * authorships.raw\_affiliation\_strings
  * authorships.affiliations
  * authorships.author.id
  * authorships.author.display\_name
  * authorships.author.orcid
  * topics.id
  * topics.display\_name
  * topics.score
  * topics.subfield.id
  * topics.subfield.display\_name
  * topics.field.id
  * topics.field.display\_name
  * topics.domain.id
  * topics.domain.display\_name
  * keywords.id
  * keywords.display\_name
  * keywords.score
  * concepts.id
  * concepts.wikidata
  * concepts.display\_name
  * concepts.level
  * concepts.score
  * mesh.descriptor\_ui
  * mesh.descriptor\_name
  * mesh.qualifier\_ui
  * mesh.qualifier\_name
  * mesh.is\_major\_topic
  * locations.is\_oa
  * locations.landing\_page\_url
  * locations.pdf\_url
  * locations.license
  * locations.license\_id
  * locations.version
  * locations.is\_accepted
  * locations.is\_published
  * locations.source.id
  * locations.source.display\_name
  * locations.source.issn\_l
  * locations.source.issn
  * locations.source.is\_oa
  * locations.source.is\_in\_doaj
  * locations.source.is\_indexed\_in\_scopus
  * locations.source.is\_core
  * locations.source.host\_organization
  * locations.source.host\_organization\_name
  * locations.source.host\_organization\_lineage
  * locations.source.host\_organization\_lineage\_names
  * locations.source.type
  * locations.source
  * sustainable\_development\_goals.id
  * sustainable\_development\_goals.score
  * sustainable\_development\_goals.display\_name
  * grants.funder
  * grants.funder\_display\_name
  * grants.award\_id
  * counts\_by\_year.year
  * counts\_by\_year.cited\_by\_count

Los siguientes son los filtros disponibles para busquedas:

All filters (51)
Abstract Available
Apc Paid (est)
Author
Authors Count
Citation Count
Citation Percentile (by Year/subfield)
Citation Percentile (year)
Continent
Corresponding Author
Corresponding Institution
Countries Count
Country
Cwts Core Source
DOI Prefix
Domain
Field
From Global South
Fulltext
Funder
FWCI
Has Repository Fulltext
In OA Source
Indexed by CrossRef
Indexed by DOAJ
Indexed by Mag Only
Indexed by ORCID
Indexed by Pubmed
Institution
Institution Type
Institutions Count
Keyword
Language
License
Open Access
Open Access Accepted
Open Access Published
Open Access Status
Publisher
Raw Affiliation String
References Count
Related to
Retracted
Source
Source Type
Subfield
Sustainable Development Goal
Title
Title & Abstract
Topic
Type
Year
"""



"""Indices por calcular:

* Numero total de citas.
* indice i10.
* indice k.
* Indice H fraccional
* autorank.

Dise√±ar la base de datos columnar en duckdb, la arquitectura de la solucion.

Escoger el autor descargar la base de datos y comenzar a ver el modelo de clasificacion para obtener graficas, hacer analisis, evolucion, kmeans, en otro, agrupamiento. por kmeans, pais, tema. redes de colaboracion, pais e institucion, analisis en series de tiempo analisis polinomial en skycitlearn, curva de gumpers.
mirar duckdb para integrar con una libreria con scikylearn y pycaret.
mirar la integracion de la base de datos columnar.
"""